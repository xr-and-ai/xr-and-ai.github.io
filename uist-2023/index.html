<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=2, user-scalable=no"
    />
    <title>UIST 2023 Workshop - XR and AI: AI-Enabled Virtual, Augmented, and Mixed Reality</title>
    <meta name="keywords" content="XR, AI, VR, AR, MR, Virtual Reality, Mixed Reality, Augmented Reality, Generative XR, Generative AI, LLM, ChatGPT, Context-Aware, Explainable AI" />
    <meta name="author" content="Ryo Suzuki, Mar Gonzalez-Franco, Misha Sra, and David Lindlbauer" />
    <meta name="theme-color" content="#ffffff" />
    <meta
      name="description"
      content="The advent of generative AI, large language models, and new foundation models in computer vision have fostered numerous technological innovations in AI research and its applications. However, interface design and interaction with AI technologies is predominantly confined to graphical user interfaces (GUIs) on computers or smartphones. We believe that the next step in Human-AI Interaction should be oriented towards real-world AI interfaces, where the AI technology naturally and seamlessly integrates into our everyday life by blending bits and atoms. Towards this goal, this workshop aims to unite experts and practitioners in XR and AI to envision the future of AI-enabled virtual, augmented, and mixed reality experiences. Our expansive discussion includes a variety of key topics: Generative XR, Large Language Models (LLMs) for XR, Adaptive and Context-Aware XR, Explainable AI for XR, and harnessing AI to enhance and prototype XR experiences."
    />
    <meta property="og:title" content="UIST 2023 Workshop - XR and AI: AI-Enabled Virtual, Augmented, and Mixed Reality" />
    <meta property="og:description" content="The advent of generative AI, large language models, and new foundation models in computer vision have fostered numerous technological innovations in AI research and its applications. However, interface design and interaction with AI technologies is predominantly confined to graphical user interfaces (GUIs) on computers or smartphones. We believe that the next step in Human-AI Interaction should be oriented towards real-world AI interfaces, where the AI technology naturally and seamlessly integrates into our everyday life by blending bits and atoms. Towards this goal, this workshop aims to unite experts and practitioners in XR and AI to <b>envision the future of AI-enabled virtual, augmented, and mixed reality experiences</b>. Our expansive discussion includes a variety of key topics: Generative XR, Large Language Models (LLMs) for XR, Adaptive and Context-Aware XR, Explainable AI for XR, and harnessing AI to enhance and prototype XR experiences." />
    <meta property="og:image" content="https://xr-and-ai.github.io/images/thumbnails/thumbnail-1.jpg" />
    <meta property="og:type" content="website" />

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css" type="text/css"/>
    <link rel="stylesheet" href="./style.css" type="text/css"/>
  </head>

  <body id="root">
    <div class="ui inverted vertical center aligned segment">
      <nav class="ui container">
        <h1 class="ui inverted header">UIST 2023</h1>
        <div class="ui borderless inverted compact menu">
          <a class="active item" href="#">Home</a>
          <a class="item" href="#organizers">Organizers</a>
          <a class="item" href="#topics">Topics</a>
          <a class="item" href="#agenda">Agenda</a>
        </div>
      </nav>
      <div class="ui content container">
        <h1 id="title" class="ui inverted header">XR and AI</h1>
        <h2 class="ui inverted header">AI-Enabled Virtual, Augmented, and Mixed Reality</h2>
        <p>
          Sunday, October 29th, 2023<br/>
          San Francisco, CA, USA
        </p>
        <a class="ui huge button" href="https://xr-and-ai.github.io/uist-2023.pdf" target="_blank">UIST 2023 Workshop</a>
      </div>

    </div>

    <div id="cover-images" class="ui text container">
      <div class="ui link five cards">
        <a href="https://dl.acm.org/doi/10.1145/3332165.3347945" target="_blank" class="card">
          <img src="images/crop/context-aware-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3472749.3474803" target="_blank" class="card">
          <img src="images/crop/farapy-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3526113.3545702" target="_blank" class="card">
          <img src="images/crop/realitytalk-2.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3472749.3474769" target="_blank" class="card">
          <img src="images/crop/gestuar-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3526113.3545648" target="_blank" class="card">
          <img src="images/crop/lookhere-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3544548.3581449" target="_blank" class="card">
          <img src="images/crop/teachable-reality-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3491101.3519911" target="_blank" class="card">
          <img src="images/crop/opportunistic-interfaces-2.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3472749.3474750" target="_blank" class="card">
          <img src="images/crop/semantic-adapt-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/abs/10.1145/3478120" target="_blank" class="card">
          <img src="images/crop/syncup-1.jpg">
        </a>
        <!--
        <a href="https://dl.acm.org/doi/10.1145/3544548.3581148" target="_blank" class="card">
          <img src="images/crop/thingshare-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3544548.3581566" target="_blank" class="card">
          <img src="images/crop/visual-captions-1.jpg">
        </a>
        -->
        <a href="https://dl.acm.org/doi/10.1145/3586183.3606827" target="_blank" class="card">
          <img src="images/crop/augmented-math-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3672539.3686784" target="_blank" class="card">
          <img src="images/crop/xdtk-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3379337.3415817" target="_blank" class="card">
          <img src="images/crop/wearable-subtitles-1.jpg">
        </a>
        <a href="https://dl.acm.org/doi/abs/10.1145/3544548.3581500" target="_blank" class="card">
          <img src="images/crop/xair-2.jpg">
        </a>
        <a href="https://dl.acm.org/doi/10.1145/3379337.3415881" target="_blank" class="card">
          <img src="images/crop/depthlab-1.jpg">
        </a>
        <a href="https://ego4d-data.org/" target="_blank" class="card">
          <img src="images/crop/ego4d-3.jpg">
        </a>
      </div>
    </div>


    <div id="overview" class="ui vertical stripe segment">

      <div class="ui text container">
        <h1 class="ui horizontal header divider">Overview</h1>
        <p>The advent of generative AI, large language models, and new foundation models in computer vision have fostered numerous technological innovations in AI research and its applications. However, interface design and interaction with AI technologies is predominantly confined to graphical user interfaces (GUIs) on computers or smartphones. We believe that the next step in Human-AI Interaction should be oriented towards <b>"real-world" AI interfaces, where the AI technology naturally and seamlessly integrates into our everyday life by blending bits and atoms.</b></p>
        <p>Towards this goal, this workshop aims to unite experts and practitioners in XR and AI to <b>envision the future of AI-enabled virtual, augmented, and mixed reality experiences</b>. Our expansive discussion includes a variety of key topics: Generative XR, Large Language Models (LLMs) for XR, Adaptive and Context-Aware XR, Explainable AI for XR, and harnessing AI to enhance and prototype XR experiences. We aim to identify the opportunities and challenges of how recent advances of AI could bring new XR experiences, which cannot be done before, with a keen focus on the seamless blending of our digital and physical worlds.</p>
        <a class="ui large button" href="https://xr-and-ai.github.io/uist-2023.pdf" target="_blank">Read the Proposal PDF</a>


        <h1 id="organizers" class="ui horizontal header divider">Organizers</h1>

        <div class="ui link four cards">
          <a href="https://ryosuzuki.org/" target="_blank" class="card">
            <div class="image">
              <img src="images/organizers/ryo-suzuki.jpg">
            </div>
            <div class="content">
              <div class="header">Ryo Suzuki</div>
              <div class="description">
                University of Calgary
              </div>
            </div>
          </a>

          <a href="https://margonzalezfranco.github.io/" target="_blank" class="card">
            <div class="image">
              <img src="images/organizers/mar-gonzalez-franco.jpg">
            </div>
            <div class="content">
              <div class="header">Mar Gonzalez-Franco</div>
              <div class="description">
                Google
              </div>
            </div>
          </a>

          <a href="https://sites.cs.ucsb.edu/~sra/" target="_blank" class="card">
            <div class="image">
              <img src="images/organizers/misha-sra.jpg">
            </div>
            <div class="content">
              <div class="header">Misha Sra</div>
              <div class="description">
                UC Santa Barbara
              </div>
            </div>
          </a>

          <a href="https://www.davidlindlbauer.com/" target="_blank" class="card">
            <div class="image">
              <img src="images/organizers/david-lindlbauer.jpg">
            </div>
            <div class="content">
              <div class="header">David Lindlbauer</div>
              <div class="description">
                Carnegie Mellon University
              </div>
            </div>
          </div>
        </a>

        <h1 id="topics" class="ui horizontal header divider">Topics of Interest</h1>

        <p>This workshop welcomes HCI researchers and practitioners in XR (VR/AR/MR), AI, machine learning, and computational interaction domains to share diverse perspectives and expertise. There are several domains that are not fully explored yet in the literature of XR and AI. We plan to discuss the topics that include but are not limited to the following areas:</p>

        <p class="ui bulleted list">
          <p class="item"><i><b>Generative XR:</b><br/>
          We explore the integration of generative AI for XR applications. For example, we are interested in understanding how generative AI can leverage the unique physical and spatial aspects of XR applications, such as 3D scene understanding and spatial and tangible interactions. What are the challenges and possibilities in such integration?</i></p>

          <p class="item"><i><b>LLMs for XR:</b><br/>
          This focuses specifically on the exploration of large language models to augment mixed reality experiences.
          How can we leverage the LLMs to naturally augment such interactions, instead of explicitly typing questions on the screen? Beyond text-based interaction, what kind of new applications are possible by integrating the recent advances in multi-modal LLMs to XR environment?</i></p>

          <p class="item"><i><b>Adaptive and Context-Aware XR:</b><br/>
          This focuses on the development of XR interfaces that seamlessly blend into the user’s everyday environment. Current research investigates how computational methods from optimization and machine learning can be leveraged to create XR interfaces that understand and adapt to the context of users and their environment.</i></p>

          <p class="item"><i><b>Explainable AI for XR:</b><br/>
          This addresses the growing need for user-friendly interfaces that help users understand, customize, and interact with mixed reality applications. It involves creating prototyping tools aimed at making XR experiences more accessible and understandable. The challenge is how to enable non-technical users to author adaptive behaviors and how conventional interface prototyping methods can be adapted for the development of adaptive XR.</i></p>

          <p class="item"><i><b>Prototyping XR with AI:</b><br/>
          As XR interfaces become more accessible to end users, lowering the barrier to design and develop XR applications becomes increasingly critical. Current tools primarily focus on developing applications and experiences for static
          contexts. Therefore, a major challenge lies in enabling non-technical users to author adaptive behaviors. This is particularly crucial in the development of tangible interfaces, which could unlock significant potential for immersive XR experiences.</i></p>

          <p class="item"><i><b>Other XR x AI Topics:</b><br/>
          We also welcome any possible XR and AI themes, such as intelligent interaction techniques, AI-enabled accessibility in XR, new evaluation methodologies, and real-worldoriented human-AI interaction.</i></p>
        </p>

        <h1 id="agenda" class="ui horizontal header divider">Agenda</h1>

        <p class="ui bulleted list">

          <p class="item"><i><b>Introductions:</b><br/>
          The organizers will kick off the workshop with introductions. To start community building, we will also facilitate pre-workshop engagement to cultivate and propose an initial set of themes. </i></p>

          <p class="item"><i><b>Participant's Lightning Talks:</b><br/>
          Each participant will also give lighting talks highlighting their related research experience to get to know each other.</i></p>

          <p class="item"><i><b>Keynote Talks:</b><br/>
          We also invite a couple of speakers who will deliver presentations to provoke further discussions.</i></p>

          <p class="item"><i><b>First-Round Theme Discussion:</b><br/>
          Participants will collectively extrapolate themes from the presentations and shared readings. The discussed themes will be combined with the initial set of topics developed prior to the workshop to serve as guiding directions for the first round of discussions. Once a preliminary list of discussion topics has been defined, each topic will be assigned a ‘table.’ During the session, participants will rotate between tables to engage in focused discussions of topics of their choice. One participant at each table will be designated as the discussion mediator, whose responsibilities will involve guiding and documenting the discussion.</i></p>

          <p class="item"><i><b>Second-Round Theme Discussion:</b><br/>
          The second session on theme organization will begin with lightning talks by the discussion mediators summarizing earlier conversations. Participants will then collectively revisit the discussion topics, reorganizing accordingly based on the results of the first session and expert perspectives. With the refined list of topics, the remainder of the session will follow the same format as the first round of discussions.</i></p>

          <p class="item"><i><b>Closing Discussion:</b><br/>
          In this final discussion session, we will begin by regrouping and refining the list of discussion topics based on the results of the discussion sessions. The final workshop session will focus on summarizing the workshop findings and defining next steps. First, the organizers will provide a recap of the workshop activities, including the defined themes from the pre-workshop activities and a summary of the morning and afternoon discussion outcomes. The floor will then be opened for participants to contribute their reflections on the workshop discussion. A final discussion will be held around potential future directions, such as follow-up workshops and publications.</i></p>

        </p>

        <!--
        <table class="ui basic table">
          <thead>
            <tr>
              <th>Time</th>
              <th>Activity</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>09:00 - </td>
              <td>Welcome & Social ice-breakers</td>
            </tr>
            <tr>
              <td>09:30 - </td>
              <td>Keynote Talk</td>
            </tr>
            <tr>
              <td>10:30 - </td>
              <td>Lightining Talks by Participants</td>
            </tr>
            <tr>
              <td>11:30 - </td>
              <td>Small Group Discussion based on Chosen Topics</td>
            </tr>
            <tr>
              <td>12:30</td>
              <td>Lunch break</td>
            </tr>
            <tr>
              <td>13:30 - </td>
              <td>Small Group Discussion based on Chosen Topics</td>
            </tr>
            <tr>
              <td>16:00 - </td>
              <td>Large Group Discussion and Synthesis</td>
            </tr>
            <tr>
              <td>17:00</td>
              <td>Closing Discussion</td>
            </tr>
          </tbody>
        </table>
        -->

        <h1 id="contact" class="ui horizontal header divider">Join the Workshop</h1>
        <p>UIST 2023 Workshops will take open enrollment. There are limited spaces offered on first-come first-served. You can join the workshop by registering for it when you complete your <a href="https://uist.acm.org/2023/attending/#registration" target="_blank">UIST registration.</a></p>
        <p>If you have any questions, feel free to <a href="mailto:ryo.suzuki@ucalgary.ca" target="_blank">contact us</a>.</p>

      </div>
    </div>
  </div>

  </body>
</html>