<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=2, user-scalable=no"
    />
    <meta
      name="description"
      content="Semantic-UI-Forest, collection of design, themes and templates for Semantic-UI."
    />
    <meta name="keywords" content="Semantic-UI, Theme, Design, Template" />
    <meta name="author" content="PPType" />
    <meta name="theme-color" content="#ffffff" />
    <title>Cover Template for Semantic-UI</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.1/semantic.min.css" type="text/css"/>
    <link rel="stylesheet" href="./style.css" type="text/css"/>
  </head>

  <body id="root">
    <div class="ui inverted vertical center aligned segment">
      <nav class="ui container">
        <h1 class="ui inverted header">UIST 2023</h1>
        <div class="ui borderless inverted compact menu">
          <a class="active item">Home</a>
          <a class="item">Organizers</a>
          <a class="item">Topics</a>
          <a class="item">Agenda</a>
        </div>
      </nav>
      <div class="ui content container">
        <h1 class="ui inverted header">XR and AI</h1>
        <h2 class="ui inverted header">AI-Enabled Virtual, Augmented, and Mixed Reality</h2>
        <p>
          Sunday, October 29th, 2023<br/>
          San Francisco, CA, USA
        </p>
        <a class="ui huge button" href="https://xr-and-ai.github.io/uist-2023.pdf" target="_blank">UIST 2023 Workshop</a>
      </div>
    </div>

    <div class="ui vertical stripe segment">

      <div class="ui text container">
        <h1 class="ui horizontal header divider">Overview</h1>
        <p>The advent of generative AI, large language models, and new foundation models in computer vision have fostered numerous technological innovations in AI research and its applications. However, interface design and interaction with AI technologies is predominantly confined to graphical user interfaces (GUIs) on computers or smartphones. We believe that the next step in Human-AI Interaction should be oriented towards "real-world" AI interfaces, where the AI technology naturally and seamlessly integrates into our everyday life by blending bits and atoms.</p>
        <p>Towards this goal, this workshop aims to unite experts and practitioners in XR and AI to envision the future of AI-enabled virtual, augmented, and mixed reality experiences. Our expansive discussion includes a variety of key topics: Generative XR, Large Language Models (LLMs) for XR, Adaptive and Context-Aware XR, Explainable AI for XR, and harnessing AI to enhance and prototype XR experiences. We aim to identify the opportunities and challenges of how recent advances of AI could bring new XR experiences, which cannot be done before, with a keen focus on the seamless blending of our digital and physical worlds.</p>
        <a class="ui large button" href="https://xr-and-ai.github.io/uist-2023.pdf" target="_blank">Read the Proposal PDF</a>


        <h1 class="ui horizontal header divider">Organizers</h1>

        <div class="ui link four doubling cards">
          <a href="https://ryosuzuki.org/" target="_blank" class="card">
            <div class="image">
              <img src="https://ryosuzuki.org/static/images/profile.png">
            </div>
            <div class="content">
              <div class="header">Ryo Suzuki</div>
              <div class="description">
                University of Calgary
              </div>
            </div>
          </a>

          <a href="https://margonzalezfranco.github.io/" target="_blank" class="card">
            <div class="image">
              <img src="https://margonzalezfranco.github.io/MarGonzalez_files/me.jpg">
            </div>
            <div class="content">
              <div class="header">Mar Gonzalez-Franco</div>
              <div class="description">
                Google
              </div>
            </div>
          </a>

          <a href="https://sites.cs.ucsb.edu/~sra/" target="_blank" class="card">
            <div class="image">
              <img src="https://sites.cs.ucsb.edu/~sra/img/people/misha-sm.jpg">
            </div>
            <div class="content">
              <div class="header">Misha Sra</div>
              <div class="description">
                UC Santa Barbara
              </div>
            </div>
          </a>

          <a href="https://www.davidlindlbauer.com/" target="_blank" class="card">
            <div class="image">
              <img src="https://hcii.cmu.edu/sites/default/files/styles/person_portrait_image/public/images/person/lindlbauer.jpg?h=e070f2a5&itok=-HHPra5V">
            </div>
            <div class="content">
              <div class="header">David Lindlbauer</div>
              <div class="description">
                Carnegie Mellon University
              </div>
            </div>
          </div>
        </a>

        <h1 class="ui horizontal header divider">Topics of Interest</h1>

        <p>This workshop welcomes HCI researchers and practitioners in XR (VR/AR/MR), AI, machine learning, and computational interaction domains to share diverse perspectives and expertise. There are several domains that are not fully explored yet in the literature of XR and AI. We plan to discuss the topics that include but are not limited to the following areas:</p>

        <p class="ui bulleted list">
          <p class="item"><i><b>Generative XR:</b><br/>
          We explore the integration of generative AI for XR applications. For example, we are interested in understanding how generative AI can leverage the unique physical and spatial aspects of XR applications, such as 3D scene understanding and spatial and tangible interactions. What are the challenges and possibilities in such integration?</i></p>

          <p class="item"><i><b>LLMs for XR:</b><br/>
          This focuses specifically on the exploration of large language models to augment mixed reality experiences.
          How can we leverage the LLMs to naturally augment such interactions, instead of explicitly typing questions on the screen? Beyond text-based interaction, what kind of new applications are possible by integrating the recent advances in multi-modal LLMs to XR environment?</i></p>

          <p class="item"><i><b>Adaptive and Context-Aware XR:</b><br/>
          This focuses on the development of XR interfaces that seamlessly blend into the userâ€™s everyday environment. Current research investigates how computational methods from optimization and machine learning can be leveraged to create XR interfaces that understand and adapt to the context of users and their environment.</i></p>

          <p class="item"><i><b>Explainable AI for XR:</b><br/>
          This addresses the growing need for user-friendly interfaces that help users understand, customize, and interact with mixed reality applications. It involves creating prototyping tools aimed at making XR experiences more accessible and understandable. The challenge is how to enable non-technical users to author adaptive behaviors and how conventional interface prototyping methods can be adapted for the development of adaptive XR.</i></p>

          <p class="item"><i><b>Prototyping XR with AI:</b><br/>
          As XR interfaces become more accessible to end users, lowering the barrier to design and develop XR applications becomes increasingly critical. Current tools primarily focus on developing applications and experiences for static
          contexts. Therefore, a major challenge lies in enabling non-technical users to author adaptive behaviors. This is particularly crucial in the development of tangible interfaces, which could unlock significant potential for immersive XR experiences.</i></p>

          <p class="item"><i><b>Other XR x AI Topics:</b><br/>
          We also welcome any possible XR and AI themes, such as intelligent interaction techniques, AI-enabled accessibility in XR, new evaluation methodologies, and real-worldoriented human-AI interaction.</i></p>
        </p>


        <h1 class="ui horizontal header divider">Agenda</h1>
        <p>The advent of generative AI, large language models, and new foundation models in computer vision have fostered numerous technological innovations in AI research and its applications. However, interface design and interaction with AI technologies is predominantly confined to graphical user interfaces (GUIs) on computers or smartphones. We believe that the next step in Human-AI Interaction should be oriented towards "real-world" AI interfaces, where the AI technology naturally and seamlessly integrates into our everyday life by blending bits and atoms.</p>
        <p>Towards this goal, this workshop aims to unite experts and practitioners in XR and AI to envision the future of AI-enabled virtual, augmented, and mixed reality experiences. Our expansive discussion includes a variety of key topics: Generative XR, Large Language Models (LLMs) for XR, Adaptive and Context-Aware XR, Explainable AI for XR, and harnessing AI to enhance and prototype XR experiences. We aim to identify the opportunities and challenges of how recent advances of AI could bring new XR experiences, which cannot be done before, with a keen focus on the seamless blending of our digital and physical worlds.</p>
        <a class="ui large button" href="https://xr-and-ai.github.io/uist-2023.pdf" target="_blank">Read the Proposal PDF</a>



      </div>



    </div>


    <div class="ui inverted vertical center aligned segment">
      <footer class="ui inverted vertical segment">
        Cover template for <a href="http://semantic-ui.com">Semantic-UI</a>, by
        <a href="https://github.com/semantic-ui-forest">@Semantic-UI-Forest</a>.
      </footer>
    </div>
  </body>
</html>